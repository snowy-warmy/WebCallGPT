<!DOCTYPE html>
<html lang="nl">
  <head>
    <meta charset="UTF-8" />
    <title>Verduurzamen Voice Chat</title>
    <style>
      body {
        font-family: system-ui, sans-serif;
        text-align: center;
        background: #f7f8fa;
        color: #222;
        padding: 3rem;
      }
      h1 { color: #007b5f; }
      button {
        margin-top: 1rem;
        font-size: 1.1rem;
        padding: 0.8rem 1.6rem;
        border: none;
        border-radius: 8px;
        background: #10a37f;
        color: #fff;
        cursor: pointer;
      }
      button:hover { background: #0d8a6f; }
      #status {
        margin-top: 2rem;
        font-family: monospace;
        color: #333;
        white-space: pre-wrap;
      }
    </style>
  </head>
  <body>
    <h1>üéôÔ∏è Verduurzamen Voice Assistant</h1>
    <p>Klik op ‚ÄúStart‚Äù en praat ‚Äî de assistent zal direct antwoorden.</p>
    <button id="start">Start</button>
    <div id="status"></div>

    <script type="module">
      const statusDiv = document.getElementById("status");
      document.getElementById("start").onclick = async () => {
        statusDiv.innerText = "üé§ Vraag microfoon toegang...";
        const mic = await navigator.mediaDevices.getUserMedia({ audio: true });
        statusDiv.innerText = "‚úÖ Microfoon actief. Verbinden met GPT...";

        // Request ephemeral key from your backend
        const session = await fetch("/session").then(r => r.json());
        if (!session?.client_secret?.value) {
          statusDiv.innerText = "‚ùå Fout bij sessie creatie.";
          return;
        }

        const token = session.client_secret.value;
        const model = "gpt-4o-realtime-preview";

        // Setup WebRTC connection
        const pc = new RTCPeerConnection();
        mic.getTracks().forEach(t => pc.addTrack(t, mic));

        pc.ontrack = (ev) => {
          const [stream] = ev.streams;
          const audio = document.createElement("audio");
          audio.autoplay = true;
          audio.srcObject = stream;
          document.body.appendChild(audio);
          statusDiv.innerText = "üó£Ô∏è GPT luistert en spreekt terug...";
        };

        const dc = pc.createDataChannel("oai-events");
        dc.onmessage = (e) => console.log("üõ∞Ô∏è", e.data);

        dc.onopen = () => {
          console.log("‚úÖ DataChannel open");
          dc.send(JSON.stringify({
            type: "session.update",
            session: {
              modalities: ["audio", "text"],
              voice: "nova",
              instructions:
                "Je bent een vriendelijke Nederlandse verduurzamingsassistent. Praat natuurlijk en geef nuttige tips.",
            },
          }));
          dc.send(JSON.stringify({
            type: "response.create",
            response: {
              modalities: ["audio", "text"],
              instructions: "Begroet me vriendelijk alsof we net beginnen te praten.",
            },
          }));
        };

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        const resp = await fetch(`https://api.openai.com/v1/realtime?model=${model}`, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${token}`,
            "Content-Type": "application/sdp",
            "OpenAI-Beta": "realtime=v1",
          },
          body: offer.sdp,
        });

        if (!resp.ok) {
          statusDiv.innerText = "‚ùå Verbinding mislukt.";
          console.error(await resp.text());
          return;
        }

        const answer = { type: "answer", sdp: await resp.text() };
        await pc.setRemoteDescription(answer);
        statusDiv.innerText = "‚úÖ Verbonden! GPT zal zo iets zeggen...";
      };
    </script>
  </body>
</html>
